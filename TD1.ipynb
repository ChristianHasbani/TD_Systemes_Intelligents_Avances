{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and Torch version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0+cu118\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as tfs\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = datasets.MNIST(\n",
    "    root='./',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=tfs.Compose([tfs.ToTensor()])\n",
    ")\n",
    "\n",
    "test_set = datasets.MNIST(\n",
    "    root='./',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=tfs.Compose([tfs.ToTensor()])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loaders and Training/Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 0\n",
    "batch_size = 128\n",
    "valid_size = 0.2\n",
    "\n",
    "num_train = len(train_set)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "train_index , valid_index = indices[split:],indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_index)\n",
    "valid_sampler = SubsetRandomSampler(valid_index)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set, batch_size, sampler=train_sampler, num_workers=num_workers)\n",
    "valid_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n",
    "                                          sampler=valid_sampler, num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size,\n",
    "                                         num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the number of truue positives by comparing the predictions and labels\n",
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP class extends nn.Module\n",
    "# Base class for all neural network modules\n",
    "class MLP(nn.Module):\n",
    "    # __init__ Initialise all layers in the NN model\n",
    "    def __init__(self):\n",
    "        super(MLP,self).__init__()\n",
    "        # nn.Linear is a FC layer (Called Dense in keras)\n",
    "        self.Input = nn.Linear (in_features=784,out_features=512)\n",
    "        # nn.Dropout with drop rate p = 0.2 used to avoid overfitting\n",
    "        self.Dropout1 = nn.Dropout(0.2)\n",
    "        self.Hidden = nn.Linear(in_features= 512, out_features= 512)\n",
    "        self.Dropout2 = nn.Dropout(0.2)\n",
    "        self.Predictions = nn.Linear (in_features=512,out_features=10)\n",
    "    \n",
    "    # Forward is used to discribe the behavior of the model during a feed forward pass\n",
    "    def forward(self, input_tensor):\n",
    "        # Flatten the w and h of the image (2D --> 1D)\n",
    "        x = torch.flatten(input_tensor,start_dim=1)\n",
    "        x = self.Input(x)\n",
    "        # Apply non linear activation function relu\n",
    "        x = F.relu(x)\n",
    "        x = self.Dropout1(x)\n",
    "        x = self.Hidden(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.Dropout2(x)\n",
    "        x = self.Predictions(x)\n",
    "        # Apply Softmax to the output of the model then return the result\n",
    "        x = F.softmax(x,dim=1)\n",
    "        return x\n",
    "    \n",
    "    # __repr__ rerturns the models architecture when called\n",
    "    def __repr__(self):\n",
    "        return super().__repr__()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 2.362790 \tValidation Loss: 0.018356 \tAccuracy: 0.098250 \tValidation Accuracy: 0.099250\n",
      "Epoch: 2 \tTraining Loss: 2.362672 \tValidation Loss: 0.018773 \tAccuracy: 0.098479 \tValidation Accuracy: 0.099250\n",
      "Epoch: 3 \tTraining Loss: 2.362672 \tValidation Loss: 0.019023 \tAccuracy: 0.098479 \tValidation Accuracy: 0.099250\n",
      "Epoch: 4 \tTraining Loss: 2.362672 \tValidation Loss: 0.019106 \tAccuracy: 0.098479 \tValidation Accuracy: 0.099250\n",
      "Epoch: 5 \tTraining Loss: 2.362672 \tValidation Loss: 0.018856 \tAccuracy: 0.098479 \tValidation Accuracy: 0.099250\n",
      "Epoch: 6 \tTraining Loss: 2.362672 \tValidation Loss: 0.019023 \tAccuracy: 0.098479 \tValidation Accuracy: 0.099250\n",
      "Epoch: 7 \tTraining Loss: 2.362672 \tValidation Loss: 0.019023 \tAccuracy: 0.098479 \tValidation Accuracy: 0.099250\n",
      "Epoch: 8 \tTraining Loss: 2.362672 \tValidation Loss: 0.018606 \tAccuracy: 0.098479 \tValidation Accuracy: 0.099250\n",
      "Epoch: 9 \tTraining Loss: 2.362672 \tValidation Loss: 0.019106 \tAccuracy: 0.098479 \tValidation Accuracy: 0.099250\n",
      "Epoch: 10 \tTraining Loss: 2.362672 \tValidation Loss: 0.018856 \tAccuracy: 0.098479 \tValidation Accuracy: 0.099250\n",
      "Epoch: 11 \tTraining Loss: 2.362672 \tValidation Loss: 0.018856 \tAccuracy: 0.098479 \tValidation Accuracy: 0.099250\n",
      "Epoch: 12 \tTraining Loss: 2.362672 \tValidation Loss: 0.018606 \tAccuracy: 0.098479 \tValidation Accuracy: 0.099250\n",
      "Epoch: 13 \tTraining Loss: 2.362672 \tValidation Loss: 0.019273 \tAccuracy: 0.098479 \tValidation Accuracy: 0.099250\n",
      "Epoch: 14 \tTraining Loss: 2.362672 \tValidation Loss: 0.018606 \tAccuracy: 0.098479 \tValidation Accuracy: 0.099250\n",
      "Epoch: 15 \tTraining Loss: 2.362672 \tValidation Loss: 0.018689 \tAccuracy: 0.098479 \tValidation Accuracy: 0.099250\n",
      "Epoch: 16 \tTraining Loss: 2.362672 \tValidation Loss: 0.019023 \tAccuracy: 0.098479 \tValidation Accuracy: 0.099250\n",
      "Epoch: 17 \tTraining Loss: 2.362672 \tValidation Loss: 0.018689 \tAccuracy: 0.098479 \tValidation Accuracy: 0.099250\n",
      "Epoch: 18 \tTraining Loss: 2.362672 \tValidation Loss: 0.018689 \tAccuracy: 0.098479 \tValidation Accuracy: 0.099250\n",
      "Epoch: 19 \tTraining Loss: 2.362672 \tValidation Loss: 0.019189 \tAccuracy: 0.098479 \tValidation Accuracy: 0.099250\n",
      "Epoch: 20 \tTraining Loss: 2.362672 \tValidation Loss: 0.019273 \tAccuracy: 0.098479 \tValidation Accuracy: 0.099250\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "# Initialiwiwng an instance of MLP class\n",
    "model = MLP()\n",
    "# Specifying the optimizer that will be used to calculate the Backpropagation \n",
    "# here RMSprop and specify the learning rate = 0.01\n",
    "optimizer = optim.RMSprop(model.parameters(),lr=0.01)\n",
    "# Initializing Tensorboard to store scalars in the specified directory\n",
    "writer = SummaryWriter(log_dir='/mnt/d/VSCode/TD_Systèmes_Intelligents_Avancés/Results/MLP/')\n",
    "# Number of epochs to train the model\n",
    "n_epochs = 20\n",
    "# Iterate through the entire dataset based on the number of epochs specified\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    train_correct = 0\n",
    "    val_correct = 0\n",
    "    # Changing model state to train\n",
    "    model.train()\n",
    "    for batch in train_loader: # Get batch\n",
    "        images, labels = batch\n",
    "        # Sets the gradients of all optimized torch tensors to 0\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(images) # Pass or forward batch\n",
    "        loss = F.cross_entropy(preds, labels) # Calculate loss using cross entropy multiclass\n",
    "        loss.backward() # Calculate Gradients\n",
    "        optimizer.step() # Update weights\n",
    "        # Add batch loss value to train loss (We want the mean)\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        # Add batch TP (True positive) value to train correct (We want the mean accuracy)\n",
    "        train_correct += get_num_correct(preds, labels)\n",
    "    model.eval()\n",
    "    # Get batch from validation set\n",
    "    for batch in valid_loader:\n",
    "        images, labels = batch\n",
    "        preds = model(images)\n",
    "        loss = F.cross_entropy(preds,labels)\n",
    "        val_loss = loss.item() * images.size(0)\n",
    "        val_correct += get_num_correct(preds,labels)\n",
    "    # Calculating the epochs values for loss acc val_loss and val_accuracy\n",
    "    train_loss = train_loss / len(train_loader.sampler)\n",
    "    val_loss = val_loss / len(valid_loader.sampler)\n",
    "    accuracy = train_correct / len(train_loader.sampler)\n",
    "    val_accuracy = val_correct / len(valid_loader.sampler)\n",
    "    # Adding these scalar to tensorboard usinf add_scalar function\n",
    "    writer.add_scalar('Loss/loss', train_loss, epoch+1)\n",
    "    writer.add_scalar('Loss/val_loss', val_loss, epoch+1)\n",
    "    writer.add_scalar('Accuracy/acc', accuracy, epoch+1)\n",
    "    writer.add_scalar('Accuracy/val_acc', val_accuracy, epoch+1)\n",
    "    # Showing the epochs scalar values\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\tAccuracy: {:.6f} \\tValidation Accuracy: {:.6f}'.format(\n",
    "        epoch+1, \n",
    "        train_loss,\n",
    "        val_loss,\n",
    "        accuracy,\n",
    "        val_accuracy\n",
    "        ))\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
